#!meta

{"kernelInfo":{"defaultKernelName":null,"items":[{"name":"csharp","languageName":"C#","aliases":["c#","cs"]},{"name":"fsharp","languageName":"F#","aliases":["f#","fs"]},{"name":"pwsh","languageName":"PowerShell","aliases":["powershell"]},{"name":"javascript","languageName":"JavaScript","aliases":["js"]},{"name":"html","languageName":"HTML"},{"name":"sql","languageName":"SQL"},{"name":"kql","languageName":"KQL"},{"name":"mermaid","languageName":"Mermaid"},{"name":"http","languageName":"HTTP"},{"name":"value"}]}}

#!csharp

#!import ../dotenv.cs
#r "nuget: Microsoft.SemanticKernel"
#r "nuget: Microsoft.Extensions.Logging"
#r "nuget: Microsoft.Extensions.Logging.Console"
#r "nuget: Microsoft.Extensions.Logging.Debug"

#!markdown

Now we declare an HttpClient Handler that is capable of `redirecting the call to api.openai.com to local LM Studio instance`. This technique has the advantage of working without direct support of Semantic Kernel or other libraries.

#!csharp

using System.Net.Http;
using System.Threading;

private class ProxyOpenAIHandler : HttpClientHandler
{
    protected override Task<HttpResponseMessage> SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)
    {
        if (request.RequestUri != null && request.RequestUri.Host.Equals("api.openai.com", StringComparison.OrdinalIgnoreCase))
        {
            // Redirect to your local LLM server
            request.RequestUri = new Uri($"http://localhost:1234{request.RequestUri.PathAndQuery}");
        }
        return base.SendAsync(request, cancellationToken);
    }
}

#!markdown

Now you configure `openai api access` but you can avoid specifiyng API key or other paramters except passing the HttpClient with the handler created above

#!csharp

// Now configure kernel memory
using Microsoft.SemanticKernel;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;

// Register the HttpClient in the KernelBuilder's services
var kernelBuilder = Kernel.CreateBuilder();
//kernelBuilder.Services.AddSingleton<HttpClient>(httpClient);

kernelBuilder.Services.AddLogging(l => l
    .SetMinimumLevel(LogLevel.Warning)
    .AddConsole()
    .AddDebug()
);
var kernel = kernelBuilder
    .AddOpenAIChatCompletion("xxx", "xxx", httpClient: new HttpClient(new ProxyOpenAIHandler())
    { 
        Timeout = TimeSpan.FromMinutes(10)      
    })
    .Build();

#!markdown

Now interact as usual with Semantic Kernel library.

#!csharp

var kernel = kernelBuilder.Build();
var result = await kernel.InvokePromptAsync("Which is the capital of France. Answer as pirate Barbossa!!!");
Console.WriteLine(result);

#!csharp

//if your model is multimodal you can send images 
using Microsoft.SemanticKernel.ChatCompletion;
var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();

#!csharp

using Microsoft.SemanticKernel.Connectors.OpenAI;
using System.ComponentModel;

//Define the function
var describeLambda = [Description("Describe image")] (
    [Description("Short description")] string shortDescription,
    [Description("Long description")] string longDescription
) =>
{
   return;
};

var function = KernelFunctionFactory.CreateFromMethod(describeLambda, "describe");

#!csharp

using Microsoft.SemanticKernel.Connectors.OpenAI;
var settings = new PromptExecutionSettings
{
    FunctionChoiceBehavior = FunctionChoiceBehavior.Required([function], autoInvoke: false)
};

var oaiSettings = new OpenAIPromptExecutionSettings()
{
    MaxTokens = 1000,
    Temperature = 0,
    FunctionChoiceBehavior = FunctionChoiceBehavior.Required([function], autoInvoke: false)
};

ChatHistory chatMessages = new();
chatMessages.AddSystemMessage("you are an expert technician that will extract information from images");

// var image = "/Users/gianmariaricci/Desktop/test.png";
var image = "s:/Downloads/dreame.jpg";
var bytes = System.IO.File.ReadAllBytes(image);
var imageData = new ReadOnlyMemory<byte>(bytes);
var message = new ChatMessageContentItemCollection
{
    new TextContent("Extract a short description for this image then a longer markdown description"),
    new ImageContent(imageData, "image/png")
};

chatMessages.AddUserMessage(message);
var result = await chatCompletionService.GetChatMessageContentAsync(chatMessages, oaiSettings);    

#!csharp

var fcc = result.Items.OfType<FunctionCallContent>().Single();
Console.WriteLine("FunctionName: {0}", fcc.FunctionName); 
foreach (var arg in fcc.Arguments)
{
    Console.WriteLine("Argument: {0}={1}", arg.Key, arg.Value); 
}  

#!markdown

Now a sample call wihtout function calling

#!csharp

var oaiSettings = new OpenAIPromptExecutionSettings()
{
    MaxTokens = 1000,
    Temperature = 0,
};

ChatHistory chatMessages = new();
chatMessages.AddSystemMessage("you are an expert technician that will extract information from images");

var bytes = System.IO.File.ReadAllBytes(image);
var imageData = new ReadOnlyMemory<byte>(bytes);
var message = new ChatMessageContentItemCollection
{
    new TextContent(@"This is a page of a pdf document that represents a technical manual, please describe the page, identify images and generate a markdown that explain with great detail what is in this page.."),
    new ImageContent(imageData, "image/png")
};

chatMessages.AddUserMessage(message);
var result = await chatCompletionService.GetChatMessageContentAsync(chatMessages, oaiSettings);  
Console.WriteLine(result);  
